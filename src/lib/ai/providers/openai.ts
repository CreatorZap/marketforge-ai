import OpenAI from 'openai'

/**
 * Op√ß√µes de configura√ß√£o para gera√ß√£o de conte√∫do com IA
 * 
 * model: Qual IA usar (gpt-4o-mini √© mais barato, gpt-4o √© mais inteligente)
 * temperature: Criatividade (0 = rob√≥tico, 1 = criativo)
 * maxTokens: Tamanho m√°ximo da resposta (1 token ‚âà 4 caracteres)
 */
interface GenerationOptions {
  model?: string
  temperature?: number
  maxTokens?: number
}

/**
 * Resultado da gera√ß√£o de conte√∫do
 */
interface GenerationResult {
  content: string      // Texto gerado pela IA
  tokensUsed: number   // Quanto de "cr√©dito" foi usado
}

/**
 * Provider OpenAI - Respons√°vel por toda comunica√ß√£o com a API da OpenAI
 * 
 * O que esta classe faz:
 * - Conecta com a OpenAI usando sua API key
 * - Envia prompts e recebe respostas
 * - Trata erros (sem cr√©ditos, API fora do ar, etc)
 * - Faz retry autom√°tico se falhar
 */
export class OpenAIProvider {
  private client: OpenAI

  /**
   * Construtor - Inicializa a conex√£o com OpenAI
   * 
   * Valida se a API key existe antes de permitir uso
   * Se n√£o existir, lan√ßa erro para avisar o desenvolvedor
   */
  constructor() {
    // üîç DEBUG: Verificar API Key no construtor
    console.log('=== DEBUG OPENAI PROVIDER ===')
    console.log('OPENAI_API_KEY exists:', !!process.env.OPENAI_API_KEY)
    console.log('OPENAI_API_KEY length:', process.env.OPENAI_API_KEY?.length || 0)
    console.log('OPENAI_API_KEY starts with sk-:', process.env.OPENAI_API_KEY?.startsWith('sk-') || false)
    console.log('OPENAI_API_KEY first 10 chars:', process.env.OPENAI_API_KEY?.substring(0, 10) || 'undefined')
    console.log('OPENAI_API_KEY last 10 chars:', process.env.OPENAI_API_KEY?.substring(-10) || 'undefined')
    console.log('================================')
    
    if (!process.env.OPENAI_API_KEY) {
      throw new Error(
        '‚ùå OPENAI_API_KEY n√£o configurada! Adicione no arquivo .env.local'
      )
    }

    this.client = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY
    })
  }

  /**
   * M√©todo Principal - Gera conte√∫do usando a IA
   * 
   * @param prompt - O que voc√™ quer que a IA fa√ßa (ex: "Crie um site de vendas")
   * @param options - Configura√ß√µes opcionais (modelo, temperatura, etc)
   * @returns Objeto com o conte√∫do gerado e tokens usados
   * 
   * Exemplo de uso:
   * const result = await provider.generate("Crie uma landing page")
   * console.log(result.content) // Resposta da IA
   * console.log(result.tokensUsed) // Quanto custou
   */
  async generate(
    prompt: string, 
    options: GenerationOptions = {}
  ): Promise<GenerationResult> {
    // Valores padr√£o se n√£o forem especificados
    const {
      model = 'gpt-4o-mini',        // Modelo padr√£o (mais barato)
      temperature = 0.7,             // Equil√≠brio entre criativo e consistente
      maxTokens = 4000               // ~16.000 caracteres de resposta
    } = options

    try {
      // Chama a API da OpenAI
      const completion = await this.client.chat.completions.create({
        model,
        messages: [
          { 
            role: 'system', 
            content: 'Voc√™ √© um Senior Product Designer + Tech Lead experiente que cria especifica√ß√µes t√©cnicas detalhadas em portugu√™s brasileiro.' 
          },
          { 
            role: 'user', 
            content: prompt 
          }
        ],
        temperature,
        max_tokens: maxTokens
      })

      // Extrai a resposta
      const content = completion.choices[0].message.content || ''
      const tokensUsed = completion.usage?.total_tokens || 0

      return {
        content,
        tokensUsed
      }

    } catch (error: any) {
      // Tratamento de erros espec√≠ficos
      
      // Erro 1: Sem cr√©ditos na OpenAI
      if (error.code === 'insufficient_quota') {
        throw new Error(
          'üí≥ Cr√©ditos OpenAI esgotados! Adicione cr√©ditos em https://platform.openai.com/account/billing'
        )
      }
      
      // Erro 2: API key inv√°lida
      if (error.status === 401) {
        throw new Error(
          'üîë API Key inv√°lida! Verifique sua OPENAI_API_KEY no .env.local'
        )
      }
      
      // Erro 3: Rate limit (muitas requisi√ß√µes)
      if (error.status === 429) {
        throw new Error(
          '‚è±Ô∏è Muitas requisi√ß√µes! Aguarde alguns segundos e tente novamente.'
        )
      }
      
      // Erro gen√©rico
      throw new Error(`Erro OpenAI: ${error.message}`)
    }
  }

  /**
   * M√©todo com Retry Autom√°tico - Tenta novamente se falhar
   * 
   * Backoff Exponencial: 
   * - 1¬™ tentativa: imediato
   * - 2¬™ tentativa: espera 2s
   * - 3¬™ tentativa: espera 4s
   * - 4¬™ tentativa: espera 8s
   * 
   * @param prompt - O que voc√™ quer que a IA fa√ßa
   * @param options - Configura√ß√µes de gera√ß√£o
   * @param retries - Quantas vezes tentar novamente se falhar
   * @param currentAttempt - Tentativa atual (usado internamente para o backoff)
   * @returns Resultado da gera√ß√£o
   * 
   * Exemplo de uso:
   * // Tenta at√© 3 vezes se a OpenAI estiver lenta
   * const result = await provider.generateWithRetry(prompt, {}, 3)
   */
  async generateWithRetry(
    prompt: string, 
    options: GenerationOptions = {},
    retries: number = 2,
    currentAttempt: number = 0
  ): Promise<GenerationResult> {
    try {
      // Tenta gerar normalmente
      return await this.generate(prompt, options)
      
    } catch (error: any) {
      // Se ainda tem tentativas dispon√≠veis
      if (retries > 0) {
        // Calcula tempo de espera: 2^tentativa * 1000ms
        // Tentativa 1: 2^1 = 2s
        // Tentativa 2: 2^2 = 4s
        // Tentativa 3: 2^3 = 8s
        const backoffTime = Math.pow(2, currentAttempt + 1) * 1000
        
        console.log(
          `‚ö†Ô∏è Erro na tentativa ${currentAttempt + 1}. Tentando novamente em ${backoffTime/1000}s...`
        )
        
        // Espera o tempo calculado
        await new Promise(resolve => setTimeout(resolve, backoffTime))
        
        // Tenta novamente (recursivo)
        return this.generateWithRetry(
          prompt, 
          options, 
          retries - 1,
          currentAttempt + 1
        )
      }
      
      // Se acabaram as tentativas, lan√ßa o erro
      throw error
    }
  }
}

/**
 * Singleton - Inst√¢ncia √∫nica do OpenAIProvider
 * 
 * Por que usar singleton?
 * - Evita criar m√∫ltiplas conex√µes com a OpenAI
 * - Economiza mem√≥ria
 * - Garante que todos usem a mesma configura√ß√£o
 * 
 * Como usar em outros arquivos:
 * import { openAIProvider } from '@/lib/ai/providers/openai'
 * const result = await openAIProvider.generate("meu prompt")
 */
export const openAIProvider = new OpenAIProvider()
